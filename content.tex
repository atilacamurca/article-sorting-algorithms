\section{Introdução}

Ordenar objetos, de uma maneira geral, é bastante útil pois ajuda a
organizar, buscar de forma rápida, verificar existência, entre outros
aspectos. Em computação isso não é diferente. A ordenação é utilizada em
várias áreas, por exemplo Bancos de Dados. Com isso precisamos sempre de
algoritmos de ordenação que façam o trabalho em menos tempo, consumindo
menos recursos.

\section{Métodos de Ordenação}

Para ordenar dados computacionais precisamos de métodos, que consistem
em procedimentos que dado um conjunto geram uma saída com o próximo
elemento sempre menor ou igual ao anterior, ou vice versa.

Veremos a implementação e estatísticas dos seguintes métodos de
ordenação:

\begin{itemize}
\item
  Bubble Sort
\item
  Selection Sort
\item
  Insertion Sort
\item
  Quick Sort
\item
  Counting Sort
\item
  Radix Sort
\end{itemize}
\subsection{Bubble Sort}

Método de ordenação bastante simples de implementar e entender. A ideia
é percorrer um vetor de dados, normalmente números, e verificar de dois
em dois qual o maior. Em caso positivo trocar um com o outro.

\subsubsection{Complexidade}

Para cada elemento é preciso percorrer o vetor, mesmo que o mesmo já
esteja ordenado. Por isso dizemos que o algoritmo é $O(n^2)$.

\subsubsection{Pseudo-código}

Esse método é caracterizado pelo uso de variável auxiliar para fazer o
\emph{swap} ou troca.

\begin{verbatim}
void bubble_sort(V[], n)
begin
    k = n - 1
    for i = 1 to n do
        for j = 0 to k do
            if V[j] > V[j + 1] do
                aux = V[j]
                V[j] = V[j + 1]
                V[j + 1] = aux
            endif
        endfor
    endfor
end
\end{verbatim}
\subsection{Selection Sort}

O algoritmo inicia buscando o valor mínimo e o coloca na primeira
posição. Depois busca o segundo menor valor e o coloca na segunda
posição. Assim por diante.

\subsubsection{Complexidade}

Selecionar o menor elemento requer verificar todos os $n$ elementos
(sendo $n - 1$ comparações) e então colocá-lo na posição correta.
Encontrar o próximo requer uma busca em $n - 1$ elementos. Daí temos:

\begin{equation}
(n - 1) + (n - 2) + \cdots + 2 + 1 = \frac{n (n - 1)}{2} \in \Theta(n^2)
\end{equation}

\subsubsection{Pseudo-código}

Também possui o \emph{swap}, entretanto pode ser que o elemento já
esteja na posição correta, e deverá ser ignorado.

\begin{verbatim}
void selection_sort(V[], n)
begin
    for i = 0 to n - 1 do
        min = i
        for j = i + 1 to n do
            if V[j] < V[min] do
                min = j
            endif
        endfor
        if min != i do
            aux = V[i]
            V[i] = V[min]
            V[min] = aux
        endif
    endfor
end
\end{verbatim}
\subsection{Insertion Sort}

A ideia é, se os primeiros elementos já estão ordenados, um elemento não
ordenado pode ser inserido no conjunto ordenado no lugar adequado.

\subsubsection{Complexidade}

Para inserir o último elemento precisamos de pelo menos $n - 1$
comparações e $n - 1$ movimentos. Para inserir o penúltimo elemento
precisamos de $n - 2$ comparações e $n - 2$ movimentos. E assim por
diante. Daí podemos concluir que teremos:

\begin{equation}
2 \cdot (1 + 2 + 3 + \dots + (n - 1)) = \frac{2 \cdot (n - 1) \cdot n}{2} = (n - 1) \cdot n \in \Theta(n^2)
\end{equation}

\subsubsection{Pseudo-código}

\begin{verbatim}
void insertion_sort(V[], n)
begin
    for i = 1 to n do
        j = i
        while j != 0
                && V[j] < V[j - 1] do
            aux = V[j]
            V[j - 1] = V[j]
            V[j] = aux
            j = j - 1
        endwhile
    endfor
end
\end{verbatim}
\subsection{Counting Sort}

Diferente de todos os algoritmos vistos até aqui, esse algoritmo não usa
comparações. Para a ordenação é preciso contar quantos elementos existem
e colocá-los num array temporário onde o índice do mesmo é o valor e
cada índice representa o número de vezes que aquele valor aparece.

\subsubsection{Complexidade temporal}

O algoritmo tem tempo de execução de $\Theta(n + k)$, onde $n$ é o
número de elementos a serem ordenados e $k$ é a variação dos tais
números. Se $k = O(n)$, este algoritmo tem performance $\Theta(n)$.

\subsubsection{Complexidade espacial}

A complexidade espacial é $\Theta(n)$, onde $n$ é o tamanho do vetor que
conta os valores. Nenhuma operação de troca é necessária durante o
processo.

\subsubsection{Pseudo-código}

\begin{verbatim}
void counting_sort(V[], n, maxValue)
begin
    count[] = [maxValue + 1]
    for i = 0 to n do
        count[i] = count[i] + 1
    endfor

    z = 0
    for i = 0 to maxValue do
        while count[i] > 0 do
            V[z] = i
            z = z + 1
            count[i] = count[i] - 1
        endwhile
    endfor
end
\end{verbatim}
\subsection{Radix Sort}

\subsubsection{Complexidade}

\subsubsection{Pseudo-código}

\subsection{Algoritmo Proposto - Busca do maior e menor}

Inicialmente definimos onde o maior e o menor elementos serão colocados,
usando as variáveis \texttt{ordEsq} e \texttt{ordDir} como visto na
figura \ref{fig:passo1}.

\begin{figure}[t]
   \includegraphics[scale=0.6]{img/maior.menor.algoritmo/passo1.png}
   \caption{definir posicionamento inicial}
   \label{fig:passo1}
\end{figure}

Logo em seguida fazemos uma busca procurando o maior e o menor elementos
(Ver figura \ref{fig:passo2}).

\begin{figure}[t]
   \includegraphics[scale=0.6]{img/maior.menor.algoritmo/passo2.png}
   \caption{busca do maior e menor elementos}
   \label{fig:passo2}
\end{figure}

Ao encontrar devemos trocar o \texttt{menor} com \texttt{ordEsq} e
\texttt{maior} com \texttt{ordDir}. Logo em seguida incrementar o valor
de \texttt{ordEsq} e decrementar o valor de \texttt{ordDir} (Ver figura
\ref{fig:passo3}).

\begin{figure}[h]
   \includegraphics[scale=0.6]{img/maior.menor.algoritmo/passo3.png}
   \caption{tamanho do vetor torna-se $n - 2$}
   \label{fig:passo3}
\end{figure}

\begin{figure}[p]
   \includegraphics[scale=0.6]{img/maior.menor.algoritmo/passo4.png}
\end{figure}

Notamos que a medida que estamos ordenando, o caminho a percorrer vai
ficando cada vez menor (Ver figura \ref{fig:passo5}).

\begin{figure}[p]
   \includegraphics[scale=0.6]{img/maior.menor.algoritmo/passo5.png}
   \caption{tamanho torna-se $n - 4$}
   \label{fig:passo5}
\end{figure}

\begin{figure}[p]
   \includegraphics[scale=0.6]{img/maior.menor.algoritmo/passo6.png}
\end{figure}

\begin{figure}[p]
   \includegraphics[scale=0.6]{img/maior.menor.algoritmo/passo7.png}
   \caption{vetor ordenado}
   \label{fig:passo7}
\end{figure}

Finalmente, para um \emph{array} ímpar temos que o valor de
\texttt{ordEsq} e \texttt{ordDir} são iguais. Nessa condição não restam
elementos a serem comparados (Ver figura \ref{fig:passo7}).

\subsubsection{Complexidade}

Podemos notar que o algoritmo faz $n$ comparações iniciais. Depois faz
$n - 2$ comparações. Em seguida $n - 4$. E assim por diante.

\subsubsection{Pseudo-código}

\begin{verbatim}
void maior_menor_sort(V[], n)
begin
    ordEsq = 0, ordDir = n - 1
    for i = ordEsq to (n / 2) do
        maior = i
        menor = i
        for j = i + 1 to ordDir + 1 do
            // encontrar maior
            if V[j] > V[maior] do
                maior = j
            endif

            // encontrar menor
            if V[j] < V[menor]
                menor = j
            endif
        endfor

        if maior != i do
            aux = V[ordDir]
            V[ordDir] = V[maior]
            V[maior] = aux
        endif

        if menor != i do
            aux = V[ordEsq]
            V[ordEsq] = V[menor]
            V[menor] = aux
        endif

        ordEsq = ordEsq + 1
        ordDir = ordDir - 1

        if ordLeft == ordDir do
            break
        endif
    endfor
end
\end{verbatim}

